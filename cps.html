<!DOCTYPE html>
<html lang="en">
<head>
	<meta id="meta" name="viewport" content="width=device-width, initial-scale=1.0" />
	<title>BD Economics | CPS Microdata Guide</title>
	<link rel="stylesheet" href="add-ins/github.css">
	<link rel="stylesheet" href="style.css">
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;700;900&family=Montserrat:wght@400;700&display=swap" rel="stylesheet">
	<script src="https://use.fontawesome.com/8f99c5621e.js" defer></script>
	<meta charset="UTF-8">
	<meta name="description" content="Python tutorial: Working with Current Population Survey microdata for labor market analysis.">
	<meta name="keywords" content="Current Population Survey, CPS, CPS microdata, CPS python, Current Population Survey Python, IMF API, Economics Dashboard, Trade Network, Trade Networks, Macroeconomics Dashboard, Macroeconomic Dashboard, Markets Dashboard, Market Dashboard, U.S. Economy, U.S. Economy Dashboard, US economy, US economy dashboard, US economy charts, US economy charts pdf, NetworkX trade, international trade networks, network analysis of trade, Census Bureau CPS Python, Census Bureau CPS Pandas, BLS CPS Pandas, BLS CPS Python">
	<meta name="author" content="Brian Dew">
	<link rel="canonical" href="https://bd-econ.com/cps.html">
	<!-- Open Graph -->
	<meta property="og:title" content="CPS Microdata Guide">
	<meta property="og:description" content="Python tutorial: Working with Current Population Survey microdata for labor market analysis.">
	<meta property="og:url" content="https://bd-econ.com/cps.html">
	<meta property="og:type" content="article">
	<meta property="og:image" content="https://bd-econ.com/images/01_bdlogo.png">
	<!-- Twitter Card -->
	<meta name="twitter:card" content="summary">
	<meta name="twitter:title" content="CPS Microdata Guide">
	<meta name="twitter:description" content="Python tutorial: Working with Current Population Survey microdata for labor market analysis.">
	<meta name="twitter:image" content="https://bd-econ.com/images/01_bdlogo.png">
	<link rel="apple-touch-icon" sizes="57x57" href="favicon/apple-icon-57x57.png">
	<link rel="apple-touch-icon" sizes="60x60" href="favicon/apple-icon-60x60.png">
	<link rel="apple-touch-icon" sizes="72x72" href="favicon/apple-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="76x76" href="favicon/apple-icon-76x76.png">
	<link rel="apple-touch-icon" sizes="114x114" href="favicon/apple-icon-114x114.png">
	<link rel="apple-touch-icon" sizes="120x120" href="favicon/apple-icon-120x120.png">
	<link rel="apple-touch-icon" sizes="144x144" href="favicon/apple-icon-144x144.png">
	<link rel="apple-touch-icon" sizes="152x152" href="favicon/apple-icon-152x152.png">
	<link rel="apple-touch-icon" sizes="180x180" href="favicon/apple-icon-180x180.png">
	<link rel="icon" type="image/png" sizes="192x192"  href="favicon/android-icon-192x192.png">
	<link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="96x96" href="favicon/favicon-96x96.png">
	<link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">
	<link rel="manifest" href="favicon/manifest.json">
	<meta name="msapplication-TileColor" content="#ffffff">
	<meta name="msapplication-TileImage" content="favicon/ms-icon-144x144.png">
	<meta name="theme-color" content="#ffffff">
<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "TechArticle",
    "headline": "CPS Microdata Python Tutorial",
    "description": "Python tutorial: Working with Current Population Survey microdata for labor market analysis.",
    "author": {
        "@type": "Person",
        "name": "Brian Dew"
    },
    "publisher": {
        "@type": "Organization",
        "name": "BD Economics",
        "url": "https://bd-econ.com"
    },
    "mainEntityOfPage": "https://bd-econ.com/cps.html"
}
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PGVF5S620Y"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PGVF5S620Y');
</script>

</head>
<body>
	<nav>
		<ul class="ul_nav" id="menu">
			<li class="nav_main"> <a href="index.html">BD Economics</a> </li>
			<li><a href="about.html">About</a> </li>
			<li><a href="https://briandew.wordpress.com">Blog</a> </li>
			<li><a href="python.html" class="active">Guides &darr;</a>
				<ul class="hidden">
					<li><a href="imfapi1.html">IMF API</a></li>
					<li><a href="blsapi.html">BLS API</a></li>
					<li><a href="beaapi.html">BEA API</a></li>
					<li><a href="censusapi.html">Census API</a></li>
					<li><a href="treasuryapi.html">Treasury API</a></li>
					<li><a href="cps.html">CPS Microdata</a></li>
			</ul>
			</li>
		<li>
			<a href="reports.html">Reports &darr;</a>
			<ul class="hidden">
				<li><a href="chartbook.html">US Chartbook</a></li>
				<li><a href="indicators.html">Economic Indicators</a></li>
			</ul>
			</li>
			<li class="icon">
				<button type="button" onclick="responsiveNav()" aria-label="Toggle navigation menu" aria-expanded="false">&#9776;</button>
			</li>
		</ul>
	</nav>

	<header>
	<h1>CPS Microdata</h1>
	</header>
	<main>
	<section>
	<article class="article_code">
	<h3>Current Population Survey Microdata with Python</h3>
	<p>January 2026</p>

	<p>This tutorial shows two ways to read CPS microdata with Python:</p>
	<ul>
		<li><b>CSV method</b> - simplest approach, recommended for quick access to single months of recent data</li>
		<li><b>Struct method</b> - fastest approach, recommended for processing many months of data</li>
	</ul>

	<h5>Note: <a href="https://cps.ipums.org/cps/">IPUMS</a> provides a user-friendly interface for downloading CPS data (and other surveys). IPUMS handles the complexity of variable selection and file formatting, making it an excellent alternative to working with raw Census files directly.</h5>

	<h5>See also: Tom Augspurger's <a href="https://github.com/TomAugspurger/pycps">pycps</a> and his four-part blog series (<a href="https://tomaugspurger.net/posts/tackling-the-cps/">1</a>, <a href="https://tomaugspurger.net/posts/tackling-the-cps-2/">2</a>, <a href="https://tomaugspurger.net/posts/tackling-the-cps-3/">3</a>, <a href="https://tomaugspurger.net/posts/tackling-the-cps-4/">4</a>) as resources for working with CPS microdata in python</h5>

	<p>The <a href="https://www.census.gov/data/datasets/time-series/demo/cps/cps-basic.html">Census Basic Monthly CPS page</a> contains the microdata files (in both CSV and fixed-width format), along with data dictionaries identifying each variable name, location, value range, and whether it applies to a restricted sample.</p>

	<h4>Method 1: CSV files (recommended for single months)</h4>

	<p>Census publishes CSV files for recent months of CPS data. This is the simplest way to load CPS microdata and is useful for quick access to a limited amount of recent data. Download the CSV file from the <a href="https://www.census.gov/data/datasets/time-series/demo/cps/cps-basic.html">Census CPS page</a>.</p>

	<p>Note that CSV files are larger than the fixed-width format files, and are not available for all years.</p>

	<h5>Read and filter the data</h5>

	<p>This example calculates the employment-to-population ratio for women age 25 to 54 in December 2025. First, we read only the columns we need from the CSV file. This speeds up the code and uses less memory than reading the entire file. We then filter to our population of interest: women (<tt>pesex == 2</tt>) between ages 25 and 54.</p>

	<p>In[1]:</p>
	<pre><code class="python">import pandas as pd
import numpy as np

# Read selected columns and query for women age 25 to 54
columns = ['prtage', 'pesex', 'prempnot', 'pwcmpwgt']
df = (pd.read_csv('dec25pub.csv', usecols=columns).dropna()
        .query('pesex == 2 and 25 <= prtage <= 54'))</code></pre>

	<h5>Calculate the weighted employment rate</h5>

	<p>The CPS is a sample survey, so each observation represents many people in the population. The <tt>pwcmpwgt</tt> variable is the person-level composite weight, which tells us how many people each survey respondent represents. We create an indicator variable for employment (<tt>prempnot == 1</tt> means employed) and then calculate the weighted average to get the employment rate.</p>

	<p>In[2]:</p>
	<pre><code class="python"># Identify employed portion of group as 1 & the rest as 0
empl = np.where(df['prempnot'] == 1, 1, 0)

# Take sample weighted average of employed portion of group
epop = np.average(empl, weights=df['pwcmpwgt'])

# Print out the result to check against LNU02300062
print(f'December 2025: {epop*100:.1f}%')</code></pre>

	<pre>December 2025: 75.4%</pre>

	<p>This result matches the <a href="https://data.bls.gov/timeseries/LNU02300062">BLS published value</a> for December 2025.</p>

	<h4>Method 2: Struct method (fastest for many months)</h4>

	<p>If you are processing decades of monthly data, the struct method is the fastest approach. This method reads the fixed-width format files directly, where each variable occupies a specific position in each row of data.</p>

	<p>Download the data dictionary (e.g., <tt>January_2017_Record_Layout.txt</tt>) and the microdata file (e.g., <tt>apr17pub.dat</tt>) from the <a href="https://www.census.gov/data/datasets/time-series/demo/cps/cps-basic.html">Census CPS page</a>. This example calculates the same employment-to-population ratio for women age 25 to 54, but for April 2017.</p>

	<p>In[3]:</p>
	<pre><code class="python"># Import relevant libraries
import re, struct
import pandas as pd
import numpy as np</code></pre>

	<h5>Parse the data dictionary</h5>

	<p>The data dictionary file describes how to read the fixed-width format CPS microdata files. It tells us where each variable is located in the raw data. We manually identify four variables of interest: <tt>PRTAGE</tt> for age, <tt>PESEX</tt> for gender, <tt>PREMPNOT</tt> for employment status, and <tt>PWCMPWGT</tt> for the person-level composite weight.</p>

	<p>In[4]:</p>
	<pre><code class="python"># Read data dictionary text file
data_dict = open('January_2017_Record_Layout.txt').read()

# Manually list out the IDs for series of interest
var_names = ['PRTAGE', 'PESEX', 'PREMPNOT', 'PWCMPWGT']</code></pre>

	<p>The data dictionary text file follows a pattern that makes it machine readable. We use a regular expression to extract the variable name, length, and start/end positions. The start location is adjusted by -1 for Python's zero-based indexing. The width is stored as a string ending in <tt>s</tt>, which is the struct format code for a character.</p>

	<p>Note that data dictionaries change over time and don't follow a consistent format, so the regex pattern may need adjustment for different years.</p>

	<p>In[5]:</p>
	<pre><code class="python"># Regular expression matching series name and data dict pattern
p = f'\n({"|".join(var_names)})\s+(\d+)\s+.*?\t+.*?(\d\d*).*?(\d\d+)'

# Dictionary of variable name: [start, end, and length + 's']
d = {s[0]: [int(s[2])-1, int(s[3]), f'{s[1]}s']
     for s in re.findall(p, data_dict)}

print(d)</code></pre>

	<pre>{'PRTAGE': [121, 123, '2s'], 'PESEX': [128, 130, '2s'], 'PREMPNOT': [392, 394, '2s'], 'PWCMPWGT': [845, 855, '10s']}</pre>

	<h5>Build the struct format string</h5>

	<p>Python's <tt>struct</tt> module can efficiently parse binary data using a format string. The format string specifies which characters to keep and which to skip. For example, <tt>121x</tt> means skip 121 characters, while <tt>2s</tt> means keep the next 2 characters as a string. By chaining these together, we can extract just the variables we need from each row.</p>

	<p>In[6]:</p>
	<pre><code class="python"># Lists of variable starts, ends, and lengths
start, end, width = zip(*d.values())

# Create list of which characters to skip in each row
skip = ([f'{s - e}x' for s, e in zip(start, [0] + list(end[:-1]))])

# Create format string by joining skip and variable segments
unpack_fmt = ''.join([j for i in zip(skip, width) for j in i])
print(unpack_fmt)

# Struct can interpret row bytes with the format string
unpacker = struct.Struct(unpack_fmt).unpack_from</code></pre>

	<pre>121x2s5x2s262x2s451x10s</pre>

	<p>Reading this format string: skip 121 characters, keep 2 (age), skip 5, keep 2 (sex), skip 262, keep 2 (employment status), skip 451, keep 10 (weight).</p>

	<h5>Understanding fixed-width format</h5>

	<p>To see what the raw data looks like, here is the first line of the microdata file:</p>

	<p>In[7]:</p>
	<pre><code class="python">print(open('apr17pub.dat').readline())</code></pre>

	<pre style="white-space: pre-wrap; word-break: break-all;">000110116792163 42017 120100-1 1 1-1 115-1-1-1  15049796 1 2 1 7 2 0 205011 2  1 1-1-1-1 36 01 338600001103000   -1-1 1-1420 1 2 1 2-1 243 1-1 9-1 1-1 1 1 1 2 1 2 57 57 57 1 0 0 1 1 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 2-150-1-1 50-1-1-1-1 2-1 2-150-1 50-1-1    2 5 5-1 2 3 5 2-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 1-121 1 1 1 6-1-1-1 -1-1-1 1 2-1-1-1-1 1 2 1 6 4      -1-1       4 3 3 1 2 4-1-1 6-138-114-1 1 9-1 3-1 2 1 1 1 0-1-1-1-1  -1  -1  -1  -10-1      -10-1-1      -1      -10-1-1-1-1-1-1-1-1-1 2-1-1 2  15049796  22986106         0  16044411  15280235 0 0 1-1-1-1 0 0 1 0-1 050 0 0 0 0 1 0 0 0-1-1-1 1 0 0-1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 0 0 0-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 0 1 1 3865 1-1-1-1-1-1-1 1 1 1-1-1-1  1573071277704210  -1  -114-1-1-1-1-1 0-1-1-1-1-15050 1 1 1 2 2 2 2 2 2 2 0 0 0 0 0 0 0-1-1-1-1-1 1 1 1202020                                            A</pre>

	<p>If we skip the first 121 characters and keep the next two, we find <tt>42</tt>, which is the age of the person in the first row of the microdata.</p>

	<h5>Read the raw microdata</h5>

	<p>We open the raw CPS microdata file in binary mode and read all lines. For each row, we check if the sample weight is positive (meaning the observation should be included), then apply the unpacker to extract just the four variables we need. The result is a list of lists, where each inner list contains the values for one person.</p>

	<p>In[8]:</p>
	<pre><code class="python"># Open file (read as binary) and read lines into "raw_data"
raw_data = open('apr17pub.dat', 'rb').readlines()

wgt = d['PWCMPWGT']  # Location of sample weight variable

# Unpack and store data of interest if sample weight > 0
data = [[*map(int, unpacker(row))] for row in raw_data
        if int(row[wgt[0]:wgt[1]]) > 0]

print(data[:5])</code></pre>

	<pre>[[42, 1, 1, 15730712], [26, 2, 1, 14582612], [25, 2, 1, 20672047], [42, 2, 4, 15492377], [47, 1, 1, 18155638]]</pre>

	<h5>Create pandas dataframe</h5>

	<p>We convert the list of lists to a pandas DataFrame for easier filtering and analysis. The DataFrame is filtered to women (<tt>PESEX == 2</tt>) between ages 25 and 54. The sample weights have four implied decimal places in the raw data, so we divide by 10,000 to get the actual weight values.</p>

	<p>In[9]:</p>
	<pre><code class="python"># Pandas dataframe of women age 25 to 54
df = (pd.DataFrame(data, columns=d.keys())
      .query('PESEX == 2 and 25 <= PRTAGE <= 54')
      .assign(PWCMPWGT = lambda x: x['PWCMPWGT'] / 10000))

print(df.head().to_string(index=False))</code></pre>

	<pre>PRTAGE  PESEX  PREMPNOT   PWCMPWGT
    26      2         1  1458.2612
    25      2         1  2067.2047
    42      2         4  1549.2377
    49      2         1  1633.0038
    26      2         1  1611.2316</pre>

	<h5>Calculate the weighted employment rate</h5>

	<p>As with the CSV method, we create an indicator variable for employment (<tt>PREMPNOT == 1</tt> means employed) and calculate the weighted average using the composite weight. The result matches the <a href="https://data.bls.gov/timeseries/LNU02300062">BLS published value</a> for April 2017.</p>

	<p>In[10]:</p>
	<pre><code class="python"># Identify employed portion of group as 1 & the rest as 0
empl = np.where(df['PREMPNOT'] == 1, 1, 0)

# Take sample weighted average of employed portion of group
epop = np.average(empl, weights=df['PWCMPWGT'])

# Print out the result to check against LNU02300062
print(f'April 2017: {epop*100:.1f}%')</code></pre>

	<pre>April 2017: 72.3%</pre>

	<h4>Scaling up</h4>

	<p>These examples can be scaled up to work with multiple years of monthly data. For a project creating harmonized partial CPS extracts, see <a href="https://github.com/bdecon/econ_data/tree/master/bd_CPS">here</a>.</p>

	<h4>About the CPS</h4>

	<p>The CPS was initially deployed in 1940 to give a more accurate unemployment rate estimate, and it is still the source of the official unemployment rate. The CPS is a monthly survey of around 65,000 households. Each selected household is surveyed up to 8 times. Interviewers ask basic demographic and employment information for the first three interview months, then ask additional detailed wage questions on the 4th interview. The household is not surveyed again for eight months, and then repeats four months of interviews with detailed wage questions again on the fourth.</p>

	<p>The CPS is not a random sample, but a multi-stage stratified sample. In the first stage, each state and DC are divided into "primary sampling units". In the second stage, a sample of housing units are drawn from the selected PSUs.</p>

	<p>There are also months where each household receives supplemental questions on a topic of interest. The largest such "CPS supplement", conducted each March, is the Annual Social and Economic Supplement. The sample size for this supplement is expanded, and the respondents are asked questions about various sources of income, and about the quality of their jobs (for example, health insurance benefits). Other supplements cover topics like job tenure, or computer and internet use.</p>

	<p>The CPS is a joint product of the U.S. Census Bureau and the Bureau of Labor Statistics.</p>

	<h5>Special thanks to John Schmitt for guidance on the CPS.</h5>

	</article>
	<div class="subfooter">
	     <a href="python.html">Back to Python Examples</a>
	</div>
	</section>
	</main>

		<footer>
		<div class="footer_left">
			<p><time datetime="2026-01-17">January 17, 2026</time><br> by Brian Dew</p>
		</div>
		<div class="footer_right">
			<a href="https://github.com/bdecon/">
				<button class="button_sm"><i class="fa fa-github"></i></button>
			</a>
			<a href="https://www.linkedin.com/in/brian-dew-5788a386/">
				<button class="button_sm"><i class="fa fa-linkedin"></i></button>
			</a>
			<a href="https://twitter.com/bd_econ">
				<button class="button_sm"><i class="fa fa-twitter"></i></button>
			</a>
			<a href="https://briandew.wordpress.com/">
				<button class="button_sm"><i class="fa fa-wordpress"></i></button>
			</a>
		</div>
	</footer>
	<script>
		function responsiveNav() {
			const menu = document.getElementById("menu");
			const button = document.querySelector(".icon button");
			menu.classList.toggle("responsive");
			const expanded = menu.classList.contains("responsive");
			button.setAttribute("aria-expanded", expanded);
		}
	</script>
	<script src="add-ins/highlight.pack.js"></script>
	<script>hljs.initHighlighting();</script>
</body>
</html>
